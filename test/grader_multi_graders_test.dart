//
// AUTO-GENERATED FILE, DO NOT MODIFY!
//
// @dart=2.18

// ignore_for_file: unused_element, unused_import
// ignore_for_file: always_put_required_named_parameters_first
// ignore_for_file: constant_identifier_names
// ignore_for_file: lines_longer_than_80_chars

import 'package:openai_flutter_sdk/api.dart';
import 'package:test/test.dart';

// tests for GraderMultiGraders
void main() {
  // final instance = GraderMultiGraders();

  group('test GraderMultiGraders', () {
    // The object type, which is always `string_check`.
    // String type
    test('to test the property `type`', () async {
      // TODO
    });

    // The name of the grader.
    // String name
    test('to test the property `name`', () async {
      // TODO
    });

    // List<EvalItem> input (default value: const [])
    test('to test the property `input`', () async {
      // TODO
    });

    // The text being graded against.
    // String reference
    test('to test the property `reference`', () async {
      // TODO
    });

    // The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.
    // String operation
    test('to test the property `operation`', () async {
      // TODO
    });

    // The evaluation metric to use. One of `fuzzy_match`, `bleu`, `gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, or `rouge_l`.
    // String evaluationMetric
    test('to test the property `evaluationMetric`', () async {
      // TODO
    });

    // The source code of the python script.
    // String source_
    test('to test the property `source_`', () async {
      // TODO
    });

    // The image tag to use for the python script.
    // String imageTag
    test('to test the property `imageTag`', () async {
      // TODO
    });

    // The model to use for the evaluation. Must support structured outputs.
    // String model
    test('to test the property `model`', () async {
      // TODO
    });

    // The sampling parameters for the model.
    // Object samplingParams
    test('to test the property `samplingParams`', () async {
      // TODO
    });

    // The range of the score. Defaults to `[0, 1]`.
    // List<num> range (default value: const [])
    test('to test the property `range`', () async {
      // TODO
    });

    // The labels to assign to each item in the evaluation.
    // List<String> labels (default value: const [])
    test('to test the property `labels`', () async {
      // TODO
    });

    // The labels that indicate a passing result. Must be a subset of labels.
    // List<String> passingLabels (default value: const [])
    test('to test the property `passingLabels`', () async {
      // TODO
    });


  });

}
